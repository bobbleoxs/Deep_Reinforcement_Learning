{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load neccessary packages\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "#from model import QNetwork\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Q-network to approximate function \n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=40, fc2_units=40,fc3_units=40):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, fc3_units)\n",
    "        self.fc4=nn.Linear(fc3_units,action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x=F.relu(self.fc3(x))\n",
    "        return self.fc4(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up hypterparameters\n",
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 32         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 8        # how often to update the network\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "        # Q-Network\n",
    "        self.qnetwork_local = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.qnetwork_target = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        # Save experience in replay memory\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Learn every UPDATE_EVERY time steps.\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if len(self.memory) > BATCH_SIZE:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, eps=0.):\n",
    "        \"\"\"Returns actions for given state as per current policy.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state (array_like): current state\n",
    "            eps (float): epsilon, for epsilon-greedy action selection\n",
    "        \"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update value parameters using given batch of experience tuples.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # Get max predicted Q values (for next states) from target model\n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        # Compute Q targets for current states \n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Update target network #\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model (PyTorch model): weights will be copied from\n",
    "            target_model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up replay buffer\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "#Set up Unity Environment\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "#Examine the State and Action Spaces\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: -0.02\n",
      "Episode 200\tAverage Score: 0.342\n",
      "Episode 300\tAverage Score: 0.78\n",
      "Episode 400\tAverage Score: 2.23\n",
      "Episode 500\tAverage Score: 3.14\n",
      "Episode 600\tAverage Score: 3.79\n",
      "Episode 700\tAverage Score: 4.95\n",
      "Episode 800\tAverage Score: 5.86\n",
      "Episode 900\tAverage Score: 7.08\n",
      "Episode 1000\tAverage Score: 7.49\n",
      "Episode 1100\tAverage Score: 8.90\n",
      "Episode 1200\tAverage Score: 8.87\n",
      "Episode 1300\tAverage Score: 9.50\n",
      "Episode 1400\tAverage Score: 9.780\n",
      "Episode 1500\tAverage Score: 10.22\n",
      "Episode 1600\tAverage Score: 10.52\n",
      "Episode 1700\tAverage Score: 12.12\n",
      "Episode 1800\tAverage Score: 11.58\n",
      "Episode 1900\tAverage Score: 12.30\n",
      "Episode 2000\tAverage Score: 11.96\n",
      "Episode 2100\tAverage Score: 12.30\n",
      "Episode 2134\tAverage Score: 13.03\n",
      "Environment solved in 2034 episodes!\tAverage Score: 13.03\n",
      "training run time:\n"
     ]
    }
   ],
   "source": [
    "#Set up DQN\n",
    "\n",
    "start = time. time()\n",
    "\n",
    "def dqn(agent, n_episodes=4000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.999, train=True):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Args\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "        train (bool): flag deciding if the agent will train or just play through the episode\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=train)[brain_name]\n",
    "        state = env_info.vector_observations[0]\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps if train else 0.0)\n",
    "            env_info = env.step(action)[brain_name]\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            if train:\n",
    "                agent.step(state, action, reward, next_state, done)\n",
    "            score += reward                                # update the score\n",
    "            state = next_state                             # roll over the state to next time step\n",
    "            if done:                                       # exit loop if episode finished\n",
    "                break\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=13.0 and train:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint_dqn.pth')\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "agent = Agent(state_size=state_size, action_size=action_size, seed=0)\n",
    "scores = dqn(agent)\n",
    "\n",
    "print (\"training run time:\" . format(time. time()- start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 19.0\n"
     ]
    }
   ],
   "source": [
    "# Run trained agent\n",
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    #action = np.random.randint(action_size)        # select an action\n",
    "    action = agent.act(state, eps=0.0)\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
